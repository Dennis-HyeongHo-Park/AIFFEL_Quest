{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFMm5aNEp5AZ",
        "outputId": "c131fc7c-357f-4771-df0d-f2199275f410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
            "TensorFlow version: 2.17.1\n"
          ]
        }
      ],
      "source": [
        "%pip install keras-tuner\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner import RandomSearch\n",
        "import keras_tuner\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_t1gZyAp8s0",
        "outputId": "1d7492c1-dc3f-4975-94d4-8a88edcd842a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# DataSet load\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Train/Test 분리\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpubqgzEwZpd"
      },
      "outputs": [],
      "source": [
        "# Call Back\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',        # 모니터할 값\n",
        "        patience=5,                # 개선되지 않는 애포크 수\n",
        "        restore_best_weights=True  # 가장 나은 가중치\n",
        "        ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model.keras',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True\n",
        "        )]\n",
        "\n",
        "# Build the model using the best hyperparameters\n",
        "model = build_model(best_hps)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=callbacks)\n",
        "\n",
        "# 모델 함수\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# 튜너\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best number of filters: {best_hps.get('filters')}\")\n",
        "print(f\"Best kernel size: {best_hps.get('kernel_size')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbyuaD0zrLFP",
        "outputId": "a2d279d8-4a71-444f-d529-29d6a06ece8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 05m 13s]\n",
            "val_loss: 0.9172261555989584\n",
            "\n",
            "Best val_loss So Far: 0.8649406830469767\n",
            "Total elapsed time: 00h 22m 47s\n",
            "Best number of filters: 32\n",
            "Best kernel size: 3\n"
          ]
        }
      ],
      "source": [
        "# Call Back\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "# 모델 함수\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# 튜너\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best number of filters: {best_hps.get('filters')}\")\n",
        "print(f\"Best kernel size: {best_hps.get('kernel_size')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5u4QqN3xM3L",
        "outputId": "de82e741-85c0-4fc3-a875-a8b7f014fe78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n",
            "Best number of filters: 32\n",
            "Best kernel size: 3\n",
            "Epoch 1/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.4490 - loss: 1.5283 - val_accuracy: 0.5830 - val_loss: 1.1963\n",
            "Epoch 2/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.6420 - loss: 1.0264 - val_accuracy: 0.6545 - val_loss: 0.9891\n",
            "Epoch 3/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 0.8863 - val_accuracy: 0.6845 - val_loss: 0.9165\n",
            "Epoch 4/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.7928 - val_accuracy: 0.6891 - val_loss: 0.9322\n",
            "Epoch 5/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7537 - loss: 0.7037 - val_accuracy: 0.6632 - val_loss: 0.9989\n",
            "Epoch 6/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.6468 - val_accuracy: 0.6927 - val_loss: 0.9219\n",
            "Final Training Accuracy: 0.7661\n",
            "Final Validation Accuracy: 0.6927\n"
          ]
        }
      ],
      "source": [
        "# Call Back\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',        # 모니터할 값\n",
        "        patience=3,                # 개선되지 않는 애포크 수\n",
        "        restore_best_weights=True  # 가장 나은 가중치\n",
        "        ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model.keras',\n",
        "        monitor='val_loss',              # val_loss가 개선될 때 마다 모델의 가중치가 best_model.keras에 저장.\n",
        "        save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "\n",
        "# 모델 빌더 함수\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']  # 정확도를 모니터링\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# 튜너 설정\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "# 튜너 탐색\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# 최적의 하이퍼파라미터 얻기\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best number of filters: {best_hps.get('filters')}\")\n",
        "print(f\"Best kernel size: {best_hps.get('kernel_size')}\")\n",
        "\n",
        "# 최적의 하이퍼파라미터로 모델 빌드\n",
        "model = build_model(best_hps)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# 학습 및 검증 정확도 출력\n",
        "train_accuracy = history.history['accuracy'][-1]\n",
        "val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"Final Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IPQtDDYzxAf"
      },
      "source": [
        "Final Training Accuracy: 0.8755  \n",
        "Final Validation Accuracy: 0.7258"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
